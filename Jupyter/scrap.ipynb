{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "import h5py as hp\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def test_monotonic_increasing(sequence):\n",
    "    array = np.array([0 for _ in range(len(sequence))])\n",
    "    sequence.read_direct(array)\n",
    "    diff = np.diff(array)\n",
    "\n",
    "    print(f\"   |num non-monotonic elements = {len(diff[diff < 0])}\")\n",
    "\n",
    "def test_uniqueness(sequence):\n",
    "    array = np.array([0 for _ in range(len(sequence))])\n",
    "    sequence.read_direct(array)\n",
    "    unique_values = np.unique(array)\n",
    "\n",
    "    print(f\"   |num duplicate elements found = {len(array) - len(unique_values)}\")\n",
    "\n",
    "def test_outliers(sequence, expected_diff):\n",
    "    array = np.array([0 for _ in range(len(sequence))])\n",
    "    sequence.read_direct(array)\n",
    "    num_outliers = np.count_nonzero(array > 2*len(array)*expected_diff)\n",
    "    print(f\"   |num outliers (i.e. greater than 2*{len(array)*expected_diff}) = {num_outliers}\")\n",
    "    #if len(outliers) > 0:\n",
    "    #    print(f\"   |   outlier values = {len(outliers)}\")\n",
    "\n",
    "def test_distribution(sequence, num_channels):\n",
    "    array = np.array([0 for _ in range(len(sequence))])\n",
    "    sequence.read_direct(array)\n",
    "    distr = np.array([np.count_nonzero(array == c) for c in range(num_channels)])\n",
    "    if np.any(distr == 0):\n",
    "        print(f\"   |num channels with zero events = {np.count_nonzero(distr == 0)}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_duplicate_events(time_zero, indices, events):\n",
    "    time_zero_array = np.array([0 for _ in range(len(time_zero))])\n",
    "    time_zero.read_direct(time_zero_array)\n",
    "    events_lists = chop_events(indices, events)\n",
    "    if len(time_zero_array) != len(events_lists):\n",
    "        print(\"Events lists fuckt\")\n",
    "\n",
    "    unique_values, inverse, counts = np.unique(time_zero_array, return_counts = True, return_inverse = True)\n",
    "    for idx, uv in enumerate(unique_values):\n",
    "        if counts[idx] > 1:\n",
    "            indices = [i for i,_ in enumerate(inverse == uv)]\n",
    "            lists = [events_lists[i] for i in indices]\n",
    "            if np.all([lists[0] == l for l in lists[1:]]):\n",
    "                pass #print(\"   |Duplicates, are really duplicates\")\n",
    "            else:\n",
    "                print(\"   |Duplicates, are not really duplicates\")\n",
    "\n",
    "\n",
    "def chop_events(indices, events) -> List[Any]:\n",
    "    index_array = np.array([0 for _ in range(len(indices) + 1)])\n",
    "    indices.read_direct(index_array[:-1])\n",
    "    events_array = np.array([0 for _ in range(len(events))])\n",
    "    events.read_direct(events_array)\n",
    "    index_array[-1] = len(events_array)\n",
    "    return [events_array[i1:i2] for (i1,i2) in sliding_window_view(index_array, window_shape = 2)]\n",
    "\n",
    "\n",
    "def assess_file(file: hp.File):\n",
    "    start_time = file.get(\"/raw_data_1/start_time\")\n",
    "    end_time = file.get(\"/raw_data_1/end_time\")\n",
    "    event_id = file.get(\"/raw_data_1/detector_1/event_id\")\n",
    "    event_time_zero = file.get(\"/raw_data_1/detector_1/event_time_zero\")\n",
    "    event_index = file.get(\"/raw_data_1/detector_1/event_index\")\n",
    "\n",
    "    print(f\"frame {f}:\")\n",
    "\n",
    "    print(f\"  start = {start_time.values()}\")\n",
    "    val = end_time.get()\n",
    "    print(f\"  start = {val}\")\n",
    "    print(f\"  end = {event_time_zero.len()}\")\n",
    "    print(f\"  num frames = {event_time_zero.len()}\")\n",
    "    if event_time_zero.len() != 0:\n",
    "        test_monotonic_increasing(event_time_zero)\n",
    "        test_uniqueness(event_time_zero)\n",
    "        test_outliers(event_time_zero, 20000000)\n",
    "    \n",
    "    print(f\"  num events = {len(event_id)}\")\n",
    "    #test_duplicate_events(event_time_zero,event_index,event_id)\n",
    "    test_distribution(event_id, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 4911:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     file \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nxs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43massess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 37\u001b[0m, in \u001b[0;36massess_file\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     33\u001b[0m event_index \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/raw_data_1/detector_1/event_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  start = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m val \u001b[38;5;241m=\u001b[39m end_time\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  start = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "f1,f2 = 4911,5536\n",
    "path = \"../archive/incoming/hifi/HIFI0000\"\n",
    "\n",
    "for f in range(f1,f2):\n",
    "    try:\n",
    "        file = hp.File(f\"{path}{f}.nxs\")\n",
    "        assess_file(file)\n",
    "    except ZeroDivisionError as e:\n",
    "        print(f\"{e}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
